{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data\\train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Graph().as_default() as g:\n",
    "    inputs = tf.placeholder(\n",
    "        shape=[None, 784], dtype=tf.float32)\n",
    "    labels = tf.placeholder(\n",
    "        shape=[None, 10], dtype=tf.float32)\n",
    "    \n",
    "    # 隐藏层与输出层\n",
    "     # 隐藏层与输出层\n",
    "    cov1 = tf.keras.layers.Dense(\n",
    "        128, \n",
    "#         kernel_initializer=tf.random_normal_initializer(stddev=0.01),\n",
    "        activation=tf.nn.relu)(inputs)\n",
    "    \n",
    "#     cov2 = tf.keras.layers.Dense(\n",
    "#         128, \n",
    "#         kernel_initializer=tf.random_normal_initializer(stddev=0.01),\n",
    "#         activation=tf.nn.sigmoid)(cov1)\n",
    "    \n",
    "    cov2 = tf.keras.layers.Dense(\n",
    "        10,\n",
    "#         kernel_initializer=tf.random_normal_initializer(stddev=0.01),\n",
    "        activation=None)(cov1)\n",
    "\n",
    "    \n",
    "    output = tf.nn.softmax(cov2)\n",
    "    \n",
    "    loss = tf.reduce_mean(\n",
    "        -tf.reduce_sum(\n",
    "            labels * tf.log(output + 1e-17), axis=1))\n",
    "    \n",
    "    acc = tf.reduce_mean(tf.cast(\n",
    "        tf.equal(tf.argmax(output, axis=1),\n",
    "                 tf.argmax(labels, axis=1)), tf.float32))\n",
    "    \n",
    "    optim = tf.train.GradientDescentOptimizer(\n",
    "        learning_rate=LEARNING_RATE)\n",
    "    train_op = optim.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step     0, loss 2.2995, acc 0.1149\n",
      "step   500, loss 0.7064, acc 0.8431\n",
      "step  1000, loss 0.4078, acc 0.8831\n",
      "step  1500, loss 0.2165, acc 0.8974\n",
      "step  2000, loss 0.2401, acc 0.9093\n",
      "step  2500, loss 0.4206, acc 0.9077\n",
      "step  3000, loss 0.2306, acc 0.9130\n",
      "step  3500, loss 0.5687, acc 0.9192\n",
      "step  4000, loss 0.3743, acc 0.9247\n",
      "step  4500, loss 0.3572, acc 0.9220\n",
      "step  5000, loss 0.2663, acc 0.9261\n",
      "step  5500, loss 0.3474, acc 0.9308\n",
      "step  6000, loss 0.2890, acc 0.9339\n",
      "step  6500, loss 0.0876, acc 0.9343\n",
      "step  7000, loss 0.2856, acc 0.9301\n",
      "step  7500, loss 0.1073, acc 0.9358\n",
      "step  8000, loss 0.2572, acc 0.9405\n",
      "step  8500, loss 0.4407, acc 0.9399\n",
      "step  9000, loss 0.2557, acc 0.9361\n",
      "step  9500, loss 0.1520, acc 0.9406\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph=g) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for step in range(10000):  # 训练次数\n",
    "        batch_images, batch_labels = mnist.train.next_batch(BATCH_SIZE)\n",
    "        res_loss, _ = sess.run(\n",
    "            [loss, train_op], \n",
    "            feed_dict={\n",
    "            inputs: batch_images,\n",
    "            labels: batch_labels\n",
    "        })\n",
    "        if step % 500 == 0:\n",
    "            accs = []\n",
    "            for j in range(10000 // BATCH_SIZE):\n",
    "                batch_images, batch_labels = mnist.test.next_batch(BATCH_SIZE)\n",
    "                res_acc = sess.run(\n",
    "                    acc,\n",
    "                    feed_dict={\n",
    "                        inputs: batch_images,\n",
    "                        labels: batch_labels\n",
    "                    })\n",
    "                accs.append(res_acc)\n",
    "\n",
    "            m_acc = np.mean(accs)\n",
    "            print('step %5d, loss %2.4f, acc %.4f' % (step, res_loss, m_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
