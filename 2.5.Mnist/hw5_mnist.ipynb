{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data\\train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Graph().as_default() as g:\n",
    "    inputs = tf.placeholder(\n",
    "        shape=[None, 784], dtype=tf.float32)\n",
    "    labels = tf.placeholder(\n",
    "        shape=[None, 10], dtype=tf.float32)\n",
    "    \n",
    "    # 隐藏层与输出层\n",
    "    hidden_output = tf.keras.layers.Dense(\n",
    "        128, activation=tf.nn.relu)(inputs)\n",
    "    \n",
    "    logits = tf.keras.layers.Dense(\n",
    "        10, activation=None)(hidden_output)\n",
    "    output = tf.nn.softmax(logits)\n",
    "    \n",
    "    loss = tf.reduce_mean(\n",
    "        -tf.reduce_sum(\n",
    "            labels * tf.log(output + 1e-17), axis=1))\n",
    "    \n",
    "    acc = tf.reduce_mean(tf.cast(\n",
    "        tf.equal(tf.argmax(output, axis=1),\n",
    "                 tf.argmax(labels, axis=1)), tf.float32))\n",
    "    \n",
    "    optim = tf.train.GradientDescentOptimizer(\n",
    "        learning_rate=LEARNING_RATE)\n",
    "    train_op = optim.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step     0, loss 2.3260, acc 0.1640\n",
      "step   500, loss 0.6045, acc 0.8613\n",
      "step  1000, loss 0.3198, acc 0.8849\n",
      "step  1500, loss 0.3851, acc 0.8922\n",
      "step  2000, loss 0.2771, acc 0.9040\n",
      "step  2500, loss 0.3155, acc 0.9075\n",
      "step  3000, loss 0.4997, acc 0.9081\n",
      "step  3500, loss 0.5267, acc 0.9122\n",
      "step  4000, loss 0.4886, acc 0.9113\n",
      "step  4500, loss 0.3244, acc 0.9126\n",
      "step  5000, loss 0.2585, acc 0.9167\n",
      "step  5500, loss 0.5721, acc 0.9164\n",
      "step  6000, loss 0.1979, acc 0.9150\n",
      "step  6500, loss 0.2575, acc 0.9191\n",
      "step  7000, loss 0.4100, acc 0.9215\n",
      "step  7500, loss 0.1110, acc 0.9187\n",
      "step  8000, loss 0.2797, acc 0.9239\n",
      "step  8500, loss 0.1822, acc 0.9241\n",
      "step  9000, loss 0.4024, acc 0.9222\n",
      "step  9500, loss 0.2429, acc 0.9251\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph=g) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for step in range(10000):  # 训练次数\n",
    "        batch_images, batch_labels = mnist.train.next_batch(BATCH_SIZE)\n",
    "        res_loss, _ = sess.run(\n",
    "            [loss, train_op], \n",
    "            feed_dict={\n",
    "            inputs: batch_images,\n",
    "            labels: batch_labels\n",
    "        })\n",
    "        if step % 500 == 0:\n",
    "            accs = []\n",
    "            for j in range(10000 // BATCH_SIZE):\n",
    "                batch_images, batch_labels = mnist.test.next_batch(BATCH_SIZE)\n",
    "                res_acc = sess.run(\n",
    "                    acc,\n",
    "                    feed_dict={\n",
    "                        inputs: batch_images,\n",
    "                        labels: batch_labels\n",
    "                    })\n",
    "                accs.append(res_acc)\n",
    "\n",
    "            m_acc = np.mean(accs)\n",
    "            print('step %5d, loss %2.4f, acc %.4f' % (step, res_loss, m_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
